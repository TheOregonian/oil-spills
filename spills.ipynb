{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import xlrd;\n",
    "import math;\n",
    "import numpy as np;\n",
    "import re;\n",
    "import geopandas;\n",
    "pd.set_option('display.max_colwidth', -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Excel file.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetching Excel file.\")\n",
    "url = \"Current.xlsx\"\n",
    "# url = \"http://nrc.uscg.mil/FOIAFiles/Current.xlsx\"\n",
    "try:\n",
    "\txl = pd.ExcelFile(url)\n",
    "except:\n",
    "\tprint(\"Failed to fetch Excel file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Excel file.\n"
     ]
    }
   ],
   "source": [
    "print(\"Parsing Excel file.\")\n",
    "# Parse out sheets into separate DataFrames\n",
    "calls = xl.parse(\"CALLS\", na_values='');\n",
    "incidents = pd.read_excel(url,\"INCIDENTS\",dtype={'PIER_DOCK_NUMBER':str})\n",
    "incident_commons = xl.parse(\"INCIDENT_COMMONS\");\n",
    "incident_details = xl.parse(\"INCIDENT_DETAILS\");\n",
    "materials = xl.parse(\"MATERIAL_INVOLVED\");\n",
    "material_cr = xl.parse(\"MATERIAL_INV0LVED_CR\");\n",
    "trains = xl.parse(\"TRAINS_DETAIL\");\n",
    "traincars = xl.parse(\"DERAILED_UNITS\");\n",
    "vessels = xl.parse(\"VESSELS_DETAIL\");\n",
    "vehicles = xl.parse(\"MOBILE_DETAILS\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pretty date string for use in naming files later\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Assemble all one-to-one tables into one big table\n",
    "incident_commons = pd.merge(incident_commons,calls, on='SEQNOS')\n",
    "incident_commons = pd.merge(incident_commons,incidents, on='SEQNOS')\n",
    "incident_commons = pd.merge(incident_commons,incident_details, on='SEQNOS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing out files.\n"
     ]
    }
   ],
   "source": [
    "# Pull up our file showing the ID of the last record processed in the \"Current.xls\" file\n",
    "# The file just keeps getting bigger every Sunday until calendar year end.\n",
    "# --------------------------------------------------------------------------\n",
    "# NOTE!!!!! If you are running this the first time, you want to delete the file\n",
    "# called \"bookmark\" from your folder\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "exists = os.path.isfile('bookmark')\n",
    "if exists:\n",
    "    bookmark = pd.read_csv(\"bookmark\")\n",
    "    appending = True\n",
    "else:\n",
    "    appending = False\n",
    "\n",
    "if appending:\n",
    "\t# Drop all the old records that we've already processed\n",
    "\tincident_commons = incident_commons[incident_commons.SEQNOS > int(bookmark.top[0])]\n",
    "\tmaterials = materials[materials.SEQNOS > int(bookmark.top[0])]\n",
    "\tmaterial_cr = material_cr[material_cr.SEQNOS > int(bookmark.top[0])]\n",
    "\ttrains = trains[trains.SEQNOS > int(bookmark.top[0])]\n",
    "\ttraincars = traincars[traincars.SEQNOS > int(bookmark.top[0])]\n",
    "\tvessels = vessels[vessels.SEQNOS > int(bookmark.top[0])]\n",
    "\tvehicles = vehicles[vehicles.SEQNOS > int(bookmark.top[0])]\n",
    "\n",
    "print(\"Writing out files.\")\n",
    "\n",
    "# Export many-to-one tables as separate files for import\n",
    "materials.to_csv('materials' + now + '.csv')\n",
    "material_cr.to_csv('material_cr' + now + '.csv')\n",
    "trains.to_csv('trains' + now + '.csv')\n",
    "traincars.to_csv('traincars' + now + '.csv')\n",
    "vessels.to_csv('vessels' + now + '.csv')\n",
    "vehicles.to_csv('vehicles' + now + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing coordinates.\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing coordinates.\")\n",
    "\n",
    "# Use full coordinates if available\n",
    "incident_commons['new_latitude']  = incident_commons.LAT_DEG + (incident_commons.LAT_MIN / 60) + (incident_commons.LAT_SEC / 3600)\n",
    "incident_commons['new_longitude'] = incident_commons.LONG_DEG + (incident_commons.LONG_MIN / 60) + (incident_commons.LONG_SEC / 3600)\n",
    "incident_commons['new_latquad']   = incident_commons.LAT_QUAD\n",
    "incident_commons['new_longquad']  = incident_commons.LONG_QUAD\n",
    "\n",
    "# Basic coordinate cleaning function, from string to float\n",
    "def splitclean(latitude):\n",
    "    if isinstance(latitude,float):\n",
    "        latitude = str(latitude)\n",
    "    # Clear out extraneous characters\n",
    "    latitude = re.sub(r'[A-Za-z]|\\/|\\'|\\\"|\\&|\\:|[\\x00-\\x1F\\x80-\\xFF]','',latitude)\n",
    "    latitude = re.sub(r'\\-',' ',latitude)\n",
    "    latitude = re.sub(r' {2,}',' ',latitude)\n",
    "    latitude = re.sub(r'\\\\p{C}','',latitude)\n",
    "    latitude = re.sub(r'([0-9]{1,2}) (\\..*)',r'\\1' + r'\\2',latitude)\n",
    "    latitude = latitude.strip()\n",
    "    # Break the string into components likely to be degrees, minutes and seconds\n",
    "    components= latitude.split(' ')\n",
    "    degrees = float; minutes = float; seconds = float;\n",
    "    for i in range(len(components)):\n",
    "        # No double decimal; ignore any digits after the second one\n",
    "        components[i] = re.sub(r'\\..*(\\..*)',r'\\0',components[i])\n",
    "        # No leading and trailing zeroes\n",
    "        components[i] = components[i].strip('0')\n",
    "        # Only numeric characters and decimal points\n",
    "        components[i] = re.sub(r'[^0-9.]+','',components[i])\n",
    "        # No leading and trailing spaces\n",
    "        components[i] = components[i].strip()\n",
    "        # No leading and trailing decimal points\n",
    "        components[i] = components[i].strip('.')\n",
    "        if i < 2: # Weird case of single number with multiple decimal points\n",
    "            components[i] = re.sub(r'\\..*(\\..*)',r'\\0',components[i])\n",
    "    if not components[0]:\n",
    "        return # Skip if empty\n",
    "    # Calculate degrees and minutes and compile into a single decimal unit\n",
    "    else:\n",
    "        degrees = float(components[0])\n",
    "    if len(components) > 1:\n",
    "        if isinstance(components[1],float):\n",
    "        \tminutes = float(components[1]) / 60\n",
    "        \tif len(components) == 3:\n",
    "        \t\tseconds = float(components[2]) / 3600\n",
    "        \t\tminutes = minutes + seconds\n",
    "        \tif degrees > 0:\n",
    "        \t\tdegrees = degrees + minutes\n",
    "        \telse:\n",
    "        \t\tdegrees = degrees - minutes\n",
    "    return degrees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Latitude from INCIDENT_LOCATION\n",
    "####################################\n",
    "\n",
    "# Start with boolean expression to operate on\n",
    "null_latitude = (incident_commons.new_latitude.isnull()) & (incident_commons.INCIDENT_LOCATION.str.extract(r'^LAT(\\/| ).*:(.*),')[1].notnull())\n",
    "\n",
    "# Find existing substring to parse for degrees, hours, minutes\n",
    "latitude = incident_commons.INCIDENT_LOCATION.str.extract(r'^LAT(\\/| ).*:(.*)(N|S),')[1]\n",
    "latquad  = incident_commons.INCIDENT_LOCATION.str.extract(r'^LAT(\\/| ).*:(.*)(N|S),')[2]\n",
    "\n",
    "# Clean the latitude\n",
    "latitude = latitude.apply(splitclean)\n",
    "\n",
    "incident_commons.loc[null_latitude,'new_latitude'] = latitude\n",
    "incident_commons.loc[null_latitude,'new_latquad']  = latquad\n",
    "\n",
    "####################################\n",
    "# Longitude from INCIDENT_LOCATION\n",
    "####################################\n",
    "\n",
    "# Find existing substring to parse for degrees, hours, minutes\n",
    "longitude = incident_commons.INCIDENT_LOCATION.str.extract(r'^LAT(\\/| ).*:(.*)(N|S), (.*?)(W|E)')[3]\n",
    "longquad  = incident_commons.INCIDENT_LOCATION.str.extract(r'^LAT(\\/| ).*:(.*)(N|S), (.*?)(W|E)')[4]\n",
    "    \n",
    "# Clean the longitude\n",
    "longitude = longitude.apply(splitclean)\n",
    "\n",
    "incident_commons.loc[null_latitude,'new_longitude'] = longitude\n",
    "incident_commons.loc[null_latitude,'new_longquad']  = longquad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Latitude and longitude from INCIDENT_LOCATION using pattern of comma split\n",
    "####################################\n",
    "\n",
    "# Start with boolean expression to operate on\n",
    "null_latitude = (incident_commons.new_latitude.isnull()) & (incident_commons.INCIDENT_LOCATION.str.extract(r'^([0-9].*),(.*)')[0].notnull())\n",
    "\n",
    "# Find existing substring to parse for degrees, hours, minutes\n",
    "latitude  = incident_commons.INCIDENT_LOCATION.str.extract(r'^([0-9].*),(.*)')[0]\n",
    "longitude = incident_commons.INCIDENT_LOCATION.str.extract(r'^([0-9].*),(.*)')[1]\n",
    "latquad   = latitude.str.extract(r'(N|S)')[0]\n",
    "longquad  = longitude.str.extract(r'(W|E)')[0]\n",
    "\n",
    "latitude  = latitude.apply(splitclean)\n",
    "longitude = longitude.apply(splitclean)\n",
    "\n",
    "incident_commons.loc[null_latitude,'new_latitude'] = latitude\n",
    "incident_commons.loc[null_latitude,'new_latquad']  = latquad\n",
    "incident_commons.loc[null_latitude,'new_longitude'] = longitude\n",
    "incident_commons.loc[null_latitude,'new_longquad']  = longquad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# LATITUDE FROM LOCATION_ADDRESS\n",
    "####################################\n",
    "\n",
    "# Start with boolean expression to operate on\n",
    "null_latitude = (incident_commons.new_latitude.isnull()) & (incident_commons.INCIDENT_LOCATION.str.extract(r'^LAT(\\:| |\\.)(.*)')[1].notnull())\n",
    "\n",
    "# Find existing substring to parse for degrees, hours, minutes\n",
    "latitude = incident_commons.LOCATION_ADDRESS.str.extract(r'^LAT(\\:| |\\.)(.*)')[1]\n",
    "latquad  = latitude.str.extract(r'(N|S)')[0]\n",
    "\n",
    "latitude  = latitude.apply(splitclean)\n",
    "\n",
    "incident_commons.loc[null_latitude,'new_latitude'] = latitude\n",
    "incident_commons.loc[null_latitude,'new_latquad']  = latquad\n",
    "\n",
    "####################################\n",
    "# LONGITUDE FROM LOCATION_ADDRESS\n",
    "####################################\n",
    "\n",
    "# Find existing substring to parse for degrees, hours, minutes\n",
    "longitude = incident_commons.LOCATION_STREET1.str.extract(r'^LONG(\\:| |\\.)(.*)')[1]\n",
    "longquad  = longitude.str.extract(r'(E|W)')\n",
    "\n",
    "longitude  = latitude.apply(splitclean)\n",
    "\n",
    "incident_commons.loc[null_latitude,'new_longitude'] = longitude\n",
    "incident_commons.loc[null_latitude,'new_longquad']  = longquad\n",
    "\n",
    "####################################\n",
    "# Latitude and longitude from LOCATION_ADDRESS using pattern of comma split\n",
    "####################################\n",
    "\n",
    "# Start with boolean expression to operate on\n",
    "null_latitude = (incident_commons.new_latitude.isnull()) & (incident_commons.LOCATION_ADDRESS.str.extract(r'^([0-9].*),(.*)')[0].notnull())\n",
    "\n",
    "# Find existing substring to parse for degrees, hours, minutes\n",
    "latitude  = incident_commons.LOCATION_ADDRESS.str.extract(r'^([0-9].*),(.*)')[0]\n",
    "longitude = incident_commons.LOCATION_ADDRESS.str.extract(r'^([0-9].*),(.*)')[1]\n",
    "latquad   = latitude.str.extract(r'(N|S)')[0]\n",
    "longquad  = longitude.str.extract(r'(W|E)')[0]\n",
    "\n",
    "latitude  = latitude.apply(splitclean)\n",
    "longitude = longitude.apply(splitclean)\n",
    "\n",
    "incident_commons.loc[null_latitude,'new_latitude'] = latitude\n",
    "incident_commons.loc[null_latitude,'new_latquad']  = latquad\n",
    "incident_commons.loc[null_latitude,'new_longitude'] = longitude\n",
    "incident_commons.loc[null_latitude,'new_longquad']  = longquad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# LATITUDE FROM LOCATION_STREET1\n",
    "####################################\n",
    "\n",
    "# Start with boolean expression to operate on\n",
    "null_latitude = (incident_commons.new_latitude.isnull()) & (incident_commons.LOCATION_STREET1.str.extract(r'^LAT(\\:| |\\.)(.*)')[1].notnull())\n",
    "\n",
    "# Find existing substring to parse for degrees, hours, minutes\n",
    "latitude = incident_commons.LOCATION_STREET1.str.extract(r'^LAT(\\:| |\\.)(.*)')[1]\n",
    "latquad  = latitude.str.extract(r'(N|S)')[0]\n",
    "\n",
    "latitude  = latitude.apply(splitclean)\n",
    "\n",
    "incident_commons.loc[null_latitude,'new_latitude'] = latitude\n",
    "incident_commons.loc[null_latitude,'new_latquad']  = latquad\n",
    "\n",
    "####################################\n",
    "# LONGITUDE FROM LOCATION_STREET1\n",
    "####################################\n",
    "\n",
    "# Find existing substring to parse for degrees, hours, minutes\n",
    "longitude = incident_commons.LOCATION_STREET2.str.extract(r'^LONG(\\:| |\\.)(.*)')[1]\n",
    "longquad  = longitude.str.extract(r'(E|W)')\n",
    "\n",
    "longitude  = latitude.apply(splitclean)\n",
    "\n",
    "incident_commons.loc[null_latitude,'new_longitude'] = longitude\n",
    "incident_commons.loc[null_latitude,'new_longquad']  = longquad\n",
    "\n",
    "####################################\n",
    "# Latitude and longitude from LOCATION_STREET1 using pattern of comma split\n",
    "####################################\n",
    "\n",
    "# Start with boolean expression to operate on\n",
    "null_latitude = (incident_commons.new_latitude.isnull()) & (incident_commons.LOCATION_STREET1.str.extract(r'^([0-9].*),(.*)')[0].notnull())\n",
    "\n",
    "# Find existing substring to parse for degrees, hours, minutes\n",
    "latitude  = incident_commons.LOCATION_STREET1.str.extract(r'^([0-9].*),(.*)')[0]\n",
    "longitude = incident_commons.LOCATION_STREET1.str.extract(r'^([0-9].*),(.*)')[1]\n",
    "latquad   = latitude.str.extract(r'(N|S)')[0]\n",
    "longquad  = longitude.str.extract(r'(W|E)')[0]\n",
    "\n",
    "latitude  = latitude.apply(splitclean)\n",
    "longitude = longitude.apply(splitclean)\n",
    "\n",
    "incident_commons.loc[null_latitude,'new_latitude'] = latitude\n",
    "incident_commons.loc[null_latitude,'new_latquad']  = latquad\n",
    "incident_commons.loc[null_latitude,'new_longitude'] = longitude\n",
    "incident_commons.loc[null_latitude,'new_longquad']  = longquad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for testing if column contains a street\n",
    "def findstreet(location):\n",
    "    if isinstance(location,float):\n",
    "        return False\n",
    "    elif location == '':\n",
    "        return False\n",
    "    else:\n",
    "        location = location.encode('utf-8')\n",
    "        location = str(location)\n",
    "        location = re.sub(r'\\\\p{C}|[\\x00-\\x1F\\x80-\\xFF]','',location)\n",
    "        if re.search(r' (RD|ROAD|AVE|AVENUE|LN|LANE|PL|PLACE|HWY|HIGHWAY|BLVD|BOULEVARD|CT|COURT|CIR|CIRCLE|ROUTE|RTE|WY|WAY)( |\\.|$)',location):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Boolean for selecting records with street\n",
    "has_street = incident_commons.LOCATION_ADDRESS.apply(findstreet) == True\n",
    "incident_commons['new_street'] = ''\n",
    "incident_commons['new_street'] = np.nan\n",
    "# Apply address if exists in loc address\n",
    "incident_commons.loc[has_street,'new_street'] = incident_commons.LOCATION_ADDRESS\n",
    "has_street = (incident_commons.LOCATION_STREET1.apply(findstreet) == True) & (incident_commons.new_street.isnull())\n",
    "# Apply address if exists in street1\n",
    "incident_commons.loc[has_street,'new_street'] = incident_commons.LOCATION_STREET1\n",
    "# Apply address if exists in incident location\n",
    "has_street = (incident_commons.INCIDENT_LOCATION.apply(findstreet) == True) & (incident_commons.new_street.isnull())\n",
    "incident_commons.loc[has_street,'new_street'] = incident_commons.INCIDENT_LOCATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting geocoder.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting geocoder.\")\n",
    "# Create geodataframe for geocoding\n",
    "geo = geopandas.GeoDataFrame(incident_commons)\n",
    "counter = 0\n",
    "from geopy.geocoders import Bing\n",
    "\n",
    "def get_apikey(servicename):\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    if os.path.isfile('/etc/apikeys'):\n",
    "        path = '/etc/apikeys'\n",
    "    else:\n",
    "        if os.path.isfile('apikeys'):\n",
    "            path = 'apikeys'\n",
    "        else:\n",
    "            return False\n",
    "    keyfile = pd.read_csv(path)\n",
    "    keydict = keyfile.to_dict('records')\n",
    "    for row in keydict:\n",
    "        if row['service'] == servicename:\n",
    "            apikey = row['key']\n",
    "            return apikey\n",
    "\n",
    "# bingkey = get_apikey('bing')\n",
    "# if bingkey == False:\n",
    "#     print \"Could not find necessary API key file.\"\n",
    "#     quit()\n",
    "\n",
    "bingkey = \"AuNPKK6wEhtJOp2JSz1iQQwqgCptimUiyamkP18Bnz4ycjMaxcFdd1kYEqyWrdxL\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Compiling address\n",
      "1 SPARTANBURG,SC\n",
      "Geocoder failed.\n",
      "2\n",
      "Compiling address\n",
      "2 SPARTANBURG,SC\n",
      "Geocoder failed.\n",
      "3\n",
      "Compiling address\n",
      "3 3235 16TH AVE SW,SEATTLE,WA\n",
      "Geocoder failed.\n",
      "4\n",
      "Compiling address\n",
      "4 3235 16TH AVE SW,SEATTLE,WA\n",
      "Geocoder failed.\n",
      "5\n",
      "Latitude already there.\n",
      "6\n",
      "Latitude already there.\n",
      "7\n",
      "Compiling address\n",
      "7 IOLA,KS\n",
      "Geocoder failed.\n",
      "8\n",
      "Compiling address\n",
      "8 IOLA,KS\n",
      "Geocoder failed.\n",
      "9\n",
      "Compiling address\n",
      "9 LAPORTE,TX\n",
      "Geocoder failed.\n",
      "10\n",
      "Compiling address\n",
      "10 LAPORTE,TX\n",
      "Geocoder failed.\n",
      "11\n",
      "Latitude already there.\n"
     ]
    }
   ],
   "source": [
    "# Compile an address string for submission to geocoder, then submit request\n",
    "\n",
    "for row in geo.itertuples():\n",
    "    if counter > 10:\n",
    "        break\n",
    "    counter+=1\n",
    "    print(counter)\n",
    "    # Skip this record for geocoding if latitude is already populated\n",
    "    if not math.isnan(row.new_latitude):\n",
    "        print(\"Latitude already there.\")\n",
    "        continue\n",
    "    # Compile the address using available street/city/county/state fields\n",
    "    print(\"Compiling address\")\n",
    "    address = ''\n",
    "    if not isinstance(row.LOCATION_STATE,float):\n",
    "        address = str(row.LOCATION_STATE)\n",
    "    if not isinstance(row.LOCATION_NEAREST_CITY,float):\n",
    "        address = str(row.LOCATION_NEAREST_CITY) + ',' + address\n",
    "    else:\n",
    "        if not isinstance(row.LOCATION_COUNTY,float):\n",
    "            address = str(row.LOCATION_COUNTY) + ' COUNTY,' + address\n",
    "    if not isinstance(row.new_street,float):\n",
    "        address = str(row.new_street) + ',' + address\n",
    "    if address == '':\n",
    "        if not isinstance(row.INCIDENT_LOCATION,float):\n",
    "            address = str(row.INCIDENT_LOCATION,float)\n",
    "        else:\n",
    "            continue\n",
    "    print(str(counter) + ' ' + address)\n",
    "    # Geocode the address\n",
    "    try:\n",
    "        location = geopandas.tools.geocode(address,provider=\"Bing\",api_key=bingkey)\n",
    "        location['SEQNOS'] = row.SEQNOS\n",
    "        if counter == 1:\n",
    "            locations = geopandas.GeoDataFrame(location)\n",
    "        else:\n",
    "            locations = locations.append(location)\n",
    "        print(\"Geocoded one address.\")\n",
    "        print(location)\n",
    "    except:\n",
    "        print(\"Geocoder failed.\")\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to merge\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'locations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4d5549a0d01b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Preparing to merge'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgeo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SEQNOS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create a text file noting record ID of where we left off with the last import of data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'locations' is not defined"
     ]
    }
   ],
   "source": [
    "print('Preparing to merge')\n",
    "\n",
    "geo = geo.merge(locations,how='left',on='SEQNOS')\n",
    "\n",
    "# Create a text file noting record ID of where we left off with the last import of data.\n",
    "biggest = geo.SEQNOS.max()\n",
    "bookmark = pd.DataFrame({'top':[biggest]})\n",
    "bookmark.to_csv('bookmark')\n",
    "\n",
    "# Clean up latitudes and longitudes to proper sign based on hemisphere\n",
    "geo.new_latitude[(geo.new_latquad == 'N')|geo.new_latquad.isnull()] = abs(geo.new_latitude)\n",
    "geo.new_latitude[geo.new_latquad == 'S'] = -1 * abs(geo.new_latitude)\n",
    "geo.new_longitude[geo.new_longquad == 'E'] = abs(geo.new_longitude)\n",
    "geo.new_longitude[(geo.new_longquad == 'W')|geo.new_longquad.isnull()] = -1 * abs(geo.new_longitude)\n",
    "\n",
    "# Create a geodataframe by converting coordinate data to Point objects\n",
    "from shapely.geometry import Point\n",
    "geometry = [Point(xy) for xy in zip(geo.new_longitude, geo.new_latitude)]\n",
    "points   = geopandas.GeoDataFrame(geometry, geometry=geometry)\n",
    "\n",
    "# Boolean to specify records to update using the coordinate data\n",
    "null_coordinates = geo.geometry.isnull()\n",
    "#null_coordinates = geo.new_latitude.notnull()\n",
    "\n",
    "# Update the geometry with data from the latitude and longitude coordinates\n",
    "geo.loc[null_coordinates,'geometry'] = points\n",
    "\n",
    "# DEPRECATED -- dump to geojson\n",
    "# Output everything as a text file for use elswhere\n",
    "#jsonfile = 'spillcalls' + now + '.geojson'\n",
    "#geo.to_file(jsonfile, driver='GeoJSON')\n",
    "\n",
    "# Redo geodataframe as a regular dataframe\n",
    "export = pd.DataFrame(geo)\n",
    "# Export bulk file or update file\n",
    "if appending:\n",
    "\texport.to_csv('latest_spillcalls.csv',encoding='utf-8')\n",
    "else:\n",
    "\texport.to_csv('spillcalls-all.csv',encoding='utf-8')\n",
    "\n",
    "# Finished\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
